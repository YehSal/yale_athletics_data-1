{"cells":[{"cell_type":"code","source":["# Use dataframes to get 4 x speedup (5 minutes instead of 21 minutes per batch)\n# utilize apache spark"],"metadata":{"collapsed":true,"scrolled":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":["!pip install bs4 tqdm"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from bs4 import BeautifulSoup\nimport pandas as pd\nimport re\nfrom tqdm import tqdm, tqdm_pandas, tqdm_notebook\n"],"metadata":{"collapsed":true,"scrolled":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":["tqdm.pandas()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Host files online so they are usable with databricks.\ndf = pd.read_csv('https://dl.dropboxusercontent.com/u/25590211/yale_bios.csv.gz?raw=1', compression='gzip', engine='python')\ndf.info()"],"metadata":{"collapsed":false,"scrolled":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# combine with labels\nlabels = pd.read_csv('https://dl.dropboxusercontent.com/u/25590211/yale_bio_urls.csv?raw=1', header=None)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["print df.shape\nprint labels.shape"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["df.index= labels"],"metadata":{"collapsed":false,"scrolled":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":["df = df.drop(['Unnamed: 0'], axis=1)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["df.reset_index(level=0, inplace=True)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["df['index']"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["tuples = df.apply(lambda x: (x['index'], x['0']), axis=1)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["We'll need to break up the strings into blocks and only use the markup that we actually need."],"metadata":{}},{"cell_type":"code","source":["DF = sc.parallelize(tuples)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# the output needs to be handled 1 at a time, and then dumped out carefully.\n# df['soup'] = df['0'].progress_apply(lambda x: BeautifulSoup(x, 'lxml') )"],"metadata":{"collapsed":false,"scrolled":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# use a distributed database to handle this more performantly before\nDF.take(5)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["SOUPS = DF.map(lambda x: (x[0], BeautifulSoup(x[1], 'lxml')) if  )"],"metadata":{"collapsed":false},"outputs":[],"execution_count":17},{"cell_type":"code","source":["SOUPS.take(2)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["def tableToDict(soup):\n    \"Given a headerless table, return a dict with all the fields\"\n    table = {}\n    for row in soup.find_all('tr'):\n        cells = row.find_all('td')\n        table[str(cells[0].text.strip())] = cells[1].text.strip()\n        \n    return table\n    \ndef soupToDict(soup):\n    \"Given a player's soup blob, parse their header\"\n    playerData = tableToDict(soup.select('div.player-info')[0].find('table'))\n    playerData['name'] = soup.select('div.player-name span.name')[0].text.strip()\n    return playerData\ndef getSynopsis(soup):\n    \"Given a player's soup, split their bio information into \\\n    chunks for each strong header\"\n    \n    # Get all top level children\n#     bioPs = soup.select('div.synopsis')[0].find_all('p', recursive=False)\n    \n#     blocks= []\n#     # if their blocks are malformed, skip that block.\n#     for i, val in enumerate(bioPs):\n#         try:\n#             blocks[val.select('strong')[0].text] = val.get_text()\n#         except:\n#             printf(\"Text not detected\")\n        \n    \n    # Given the variation in blob types, just return\n    # single blob for now.\n    # Ryan Brenner: b instead of strong tags\n    # Jackson Stallings (Junior Year) - UL blobs mixed with P tags\n    # Jackson Stallings (Freshman) - Clean example\n    \n    # Sometimes, no bio\n#     http://yalebulldogs.com/sports/c-sail/2016-17/bios/buehler_patrick_nu3o?view=news\n    bio = soup.find('div',class_='synopsis')\n    return bio.get_text() if bio else None"],"metadata":{"collapsed":false},"outputs":[],"execution_count":19},{"cell_type":"code","source":["HEADERS = DF.map(lambda x: (x[0] ,  soupToDict(BeautifulSoup(x[1], 'lxml')) if (type(x[1]) == str) else {}  ))"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["HEADERS.persist()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["heads = HEADERS.collect()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# SYNOPSIS = df['0'].progress_apply(lambda x: getSynopsis(BeautifulSoup(x, 'lxml')) if (type(x) == str) else None)\nSYNOPSIS = DF.map(lambda x: (x[0] ,  getSynopsis(BeautifulSoup(x[1], 'lxml')) if (type(x[1]) == str) else {}  ))"],"metadata":{"collapsed":false,"scrolled":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":["SYNOPSIS.persist()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["save = SYNOPSIS.collect()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["TOTAL = SYNOPSIS.join(HEADERS)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["dheads = HEADERS.toDF()"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["dtotal = TOTAL.toDF()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["newDF = dtotal.toPandas()\nnewHeads = dheads.toPandas()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["newHeads.columns = ['url', 'headers']"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["newDF.columns= ['url', 'synopsis']"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["merged = pd.merge(newHeads, newDF, on='url', suffixes=['_l', '_r'])"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["indexed = merged.set_index('url')"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["indexed.to_csv('/tmp/yale_bio_parsed.csv', compression='gzip')"],"metadata":{"collapsed":false},"outputs":[],"execution_count":34},{"cell_type":"code","source":["pwd !!"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["dbutils.fs.ls(\"file:/tmp/\")"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["\ndisplay(dbutils.fs.ls(\"/FileStore/\"))"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["dbutils.fs.cp(\"file:/tmp/yale_bio_parsed.csv\", \"/FileStore/sports/yale_bio_parsed.csv.gz\")"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# access data via https://community.cloud.databricks.com/files/yale_bios.csv.gz"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["!gzip -c yale_bio_parsed.csv > yale_bio_parsed.csv.gz"],"metadata":{"collapsed":true},"outputs":[],"execution_count":40}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2.0},"version":"2.7.12","nbconvert_exporter":"python","file_extension":".py"},"name":"10-cy-parse-yale-bios-spark","notebookId":1701440757988799},"nbformat":4,"nbformat_minor":0}
